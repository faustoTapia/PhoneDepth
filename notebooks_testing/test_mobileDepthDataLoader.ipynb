{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os import environ as env\n",
    "from os import path\n",
    "from dataset_utils.md_utils import md_dataset\n",
    "from dataset_utils.mai_utils import mai_dataset\n",
    "from dataset_utils.phoneDepth_utils import phoneDepth_dataset, decompose_train_sample_in_batches, confidence_indeces\n",
    "from dataset_utils.viz_utils import visualize_multiple_imag_rows\n",
    "from dataset_utils.aug_utils import color_jitter, salty_noise, random_rotation, random_crop_and_resize, cascade_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_dir = os.environ['DATA_DIR']\n",
    "dataset_type = 'mb'\n",
    "dataset_locations = {\"md\": \"MegaDepth_v1\",\n",
    "                     \"mai\": \"MAI2021_dataset\",\n",
    "                     \"mb\": \"FTDataset\"}\n",
    "\n",
    "dataset_name = dataset_locations[dataset_type]\n",
    "data_dir = path.join(gen_data_dir, dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = 'hua'\n",
    "# io_mode = 'img2depth'\n",
    "# io_mode = \"img2projected\"\n",
    "# io_mode = \"img_depth2depth\"\n",
    "# io_mode = \"img2depth_depth\"\n",
    "# io_mode = \"img_depth2depth_depth\"\n",
    "# io_mode = \"img2depth_conf\"\n",
    "io_mode = \"img2depth_depth_conf\"\n",
    "\n",
    "conf_indx = confidence_indeces[io_mode]\n",
    "\n",
    "# Define Augmentation Functions\n",
    "jitter = color_jitter(0.9, brightness=0.1, contrast=0.1, saturation=0.1, hue = 0.1)\n",
    "salt_noise = salty_noise(0.9, 0.01)\n",
    "\n",
    "combined_img_augmentation = cascade_functions([jitter, salt_noise])\n",
    "# combined_img_augmentation = None\n",
    "\n",
    "crop_resize_transform = random_crop_and_resize(prob=0.9, min_size=0.6, max_size=1.0, img_shape= (224,224), center_crop=False, conf_indx=conf_indx)\n",
    "rotation_aug_transform = random_rotation(0.9, 2.5)\n",
    "\n",
    "# Cascaded geometric transformation\n",
    "geometric_augmentation = cascade_functions([crop_resize_transform, rotation_aug_transform])\n",
    "# geometric_augmentation = crop_resize_transform\n",
    "# geometric_augmentation = None\n",
    "\n",
    "# Note negative probability, for stability. Don't want to crop in validation\n",
    "val_geometric_transform = random_crop_and_resize(prob=-1e-5, img_shape=(128,128))\n",
    "val_geometric_transform = None\n",
    "\n",
    "shuffle = True\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "dataset_split = 'train'\n",
    "\n",
    "random_seed = 123\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "dataset_train = phoneDepth_dataset(data_dir, mode=dataset_split, input_size=(480, 640), batch_size=8, random_flip=True, shuffle=shuffle,\n",
    "                            phone=phone, io_mode=io_mode,\n",
    "                            geometric_aug_transform=geometric_augmentation, img_aug_transform=combined_img_augmentation)\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "dataset_val = phoneDepth_dataset(data_dir, mode=dataset_split, input_size=(320, 320), out_size=(480,640), batch_size=8, random_flip=False, shuffle=shuffle,\n",
    "                            phone=phone, io_mode=io_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "data_train_it = dataset_train.as_numpy_iterator()\n",
    "train_sample = data_train_it.next()\n",
    "tf.random.set_seed(seed)\n",
    "data_val_it = dataset_val.as_numpy_iterator()\n",
    "val_sample = data_val_it.next()\n",
    "\n",
    "\n",
    "train_batches = decompose_train_sample_in_batches(train_sample)\n",
    "train_batches[0] = tf.cast(train_batches[0], tf.uint8)          # For Display\n",
    "\n",
    "val_batches = decompose_train_sample_in_batches(val_sample)\n",
    "val_batches[0] = tf.cast(val_batches[0], tf.uint8)              # For Display\n",
    "\n",
    "img_batches = train_batches + val_batches\n",
    "labels = ['train_{}'.format(i) for i in range(len(train_batches))] + ['val_{}'.format(i) for i in range(len(val_batches))]\n",
    "visualize_multiple_imag_rows(img_batches, labels, n_samples = 8, histogram=True, color_map='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_batches)\n",
    "train_batches[1].shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb69225fb948715168fa792c0021e5840f68c9a1192016715b848f7eea7da002"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tf241n': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "de0bf13c9c7ef82b71a2e4ad033cfd93488f7677de8d2863c2e00aa61156b8eb"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
